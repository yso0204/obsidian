> LLM이 더 정확하고 유용한 답을 내놓도록, 적절한 정보(Context)를 잘 구성해서, 함께 제공하는 기술 혹은 설계 전략


# 왜 중요한가?
이전에는 '이거 번역해줘', ' 이 코드 봐줘' 라고 했지만,
- 복잡한 질문
- 내부 문서를 참고해야 하는 상황
- 긴 코드나 에러 로그가 있는 경우
LLM이 제대로 이해하려면, '배경 정보'가 필수

즉 단순 프롬프트 만으로는 한계가 있기에 프롬포트 + 콘텍스트를 함께 잘 구성해야 똑똑한 답을 받을 수 있다.


## Context Engineering 예시
| 상황     | 콘텍스트 엔지니어링 적용 예시                        |
| ------ | --------------------------------------- |
| 문서 Q&A | 질문에 관련 있는 문서 내용을 RAG로 추출해 함께 제공         |
| 코드 리뷰  | 프롬프트에 “현재 프로젝트의 구조”와 “코드 스타일” 정보도 함께 전달 |
| AI 챗봇  | 유저 프로필, 대화 히스토리, FAQ 문서를 context로 넣기    |
| 실험 제안  | 과거 실험 결과를 검색해 함께 넣어 실험 방향 제안            |

## 어떤 기술이 쓰이는가?
- RAG(Retrieval-Augmented Generation)
	- 문서/DB에서 필요한 정보만 찾아서 prompt에 첨부
- LangChain, LlamIndex
	- context chunking, 벡터 검색 등을 지원하는 툴
- Embeddings + Vector DB (like FAISS, Weaviate)
	- 유사한 context를 찾아주는 기술
- 프롬프트 설계
	- context가 포함된 prompt를 어떻게 구성할지 고민하는 것도 포함

|항목|RAG (Retrieval-Augmented Generation)|LangChain|
|---|---|---|
|정체|개념/기법 (AI 생성 정확도 향상을 위한 구조)|프레임워크 (RAG를 구현할 수 있는 툴킷)|
|역할|“정보 찾아서 생성에 활용하자!”는 아키텍처 개념|RAG, Agent 등 구현을 돕는 도구 모음|
|한 줄 정의|“검색 + 생성”의 구조적 설계 방식|RAG 같은 시스템을 쉽게 구현하게 해주는 Python 기반 툴|
|예시|“질문 시 관련 문서 찾아서 답 생성”|문서 chunking, vector 검색, prompt 구성 등 구현을 도와줌|
|비교 비유|‘요리 방식’|‘요리 키트’ (조리 도구 모음)|

### RAG는 개념
> 질문 -> 관련 정보를 검색 -> 이걸 바탕으로 답변을 생성

#### 구성 요소
- 질문
- Retriever(검색기)
- Generator(LLM)
```
사용자 질문 → 유사 문서 검색 (벡터 DB) →  
찾은 문서를 prompt에 넣어 GPT 호출 →  
GPT가 답변 생성
```

### LangChain은 도구/프레임워크
> RAG 시스템을 직접 만들고 싶을 때 쓰는 Python 라이브러리
> 다른 말로, RAG를 구현하기 쉽게 도와주는 조립 키트

#### LangChain으로 할 수 있는 것들
- 문서 chunking & embedding
- 벡터 DB 연결(FAISS, Pinecone 등)
- prompot 템플릿 관리
- RAG, Agent, Tool 호출 체인 구성
